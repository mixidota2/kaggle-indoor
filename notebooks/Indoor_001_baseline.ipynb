{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indoor_001_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1BvR8HA789V1HCAAyMyi5cODGRAI0dADN",
      "authorship_tag": "ABX9TyNJYCm9m8mbtkciRy1XH3fA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mixidota2/kaggle-indoor/blob/main/notebooks/Indoor_001_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iByMsYwExpm5"
      },
      "source": [
        "## Overview\n",
        "- Baselineを構築するためのnotebook\n",
        "- とりあえずデータ読んで最低限のsubをするだけを目的とする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfydvjf5tZRS",
        "outputId": "0eb9f17d-fa8f-479b-b808-df11eac019eb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 21 10:44:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv6OXDKnC4_C"
      },
      "source": [
        "import os\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpzXfheXz8pn",
        "outputId": "c49f99a1-76f5-48ae-c798-a594718cab6e"
      },
      "source": [
        "!kaggle datasets download -d kokitanisaka/indoorunifiedwifids\n",
        "!unzip indoorunifiedwifids.zip > /dev/null"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading indoorunifiedwifids.zip to /content\n",
            "100% 463M/463M [00:16<00:00, 32.6MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9hVI5XC2BWI",
        "outputId": "9b63c568-b2a3-45f7-95c3-ec5ac6c48990"
      },
      "source": [
        "!pip install memory_profiler\n",
        "%load_ext memory_profiler"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp37-none-any.whl size=30180 sha256=76cfe770097d1555ebdd8568271adb09783abcfa8608ae461f3db4fc86ebaa5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwcwo-NOq8wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012c04aa-0fe9-4345-ce36-d8e6f4dd7956"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "tqdm.pandas(position=0, leave=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLKBfnyNE_Wq"
      },
      "source": [
        "# consts\n",
        "N_SPLITS = 10\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "NUM_FEATS = 20"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9gH31gFKty"
      },
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "def get_timestamp():\n",
        "    import time\n",
        "    timestamp = ''\n",
        "    for i, d in enumerate(time.localtime()):\n",
        "        if i == 3:\n",
        "            d += 8\n",
        "        timestamp += str(d) + '-'\n",
        "        if i == 4:\n",
        "            break\n",
        "    return timestamp[:-1]\n",
        "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
        "    intermediate = np.sqrt((xhat-x)**2 + (yhat-y)**2) + 15 * np.abs(fhat-f)\n",
        "#     intermediate = np.sqrt((xhat-x)**2 + (yhat-y)**2)\n",
        "    return intermediate.sum()/xhat.shape[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnJEEwLyIg_S"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS_j1O-QtYHr"
      },
      "source": [
        "with open(f'train_all.pkl', 'rb') as f:\n",
        "  data = pickle.load( f)\n",
        "with open(f'test_all.pkl', 'rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4iftOvO25wE"
      },
      "source": [
        "# count n features\n",
        "BSSID_FEATS = [f'bssid_{i}' for i in range(NUM_FEATS)]\n",
        "RSSI_FEATS  = [f'rssi_{i}' for i in range(NUM_FEATS)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5VgTOkLFUrZ",
        "outputId": "4c9e3351-d0a5-4c0d-d39d-00642cd018ed"
      },
      "source": [
        "# get unique wifi bssids\n",
        "wifi_bssids = []\n",
        "for i in range(100):\n",
        "    wifi_bssids.extend(data.iloc[:,i].values.tolist())\n",
        "wifi_bssids = list(set(wifi_bssids))\n",
        "\n",
        "wifi_bssids_size = len(wifi_bssids)\n",
        "print(f'BSSID TYPES: {wifi_bssids_size}')\n",
        "\n",
        "wifi_bssids_test = []\n",
        "for i in range(100):\n",
        "    wifi_bssids_test.extend(test_data.iloc[:,i].values.tolist())\n",
        "wifi_bssids_test = list(set(wifi_bssids_test))\n",
        "\n",
        "wifi_bssids_size = len(wifi_bssids_test)\n",
        "print(f'BSSID TYPES: {wifi_bssids_size}')\n",
        "\n",
        "wifi_bssids.extend(wifi_bssids_test)\n",
        "wifi_bssids_size = len(wifi_bssids)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BSSID TYPES: 61206\n",
            "BSSID TYPES: 33042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhmlcJ-CF0hb",
        "outputId": "b4fdea21-c0ae-493f-da91-bbe50ce60a75"
      },
      "source": [
        "# preprocess\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(wifi_bssids)\n",
        "le_site = LabelEncoder()\n",
        "le_site.fit(data['site_id'])\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(data.loc[:,RSSI_FEATS])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdBSEoUuG8no"
      },
      "source": [
        "# apply transforms\n",
        "\n",
        "data.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])\n",
        "for i in BSSID_FEATS:\n",
        "    data.loc[:,i] = le.transform(data.loc[:,i])\n",
        "    data.loc[:,i] = data.loc[:,i] + 1\n",
        "    \n",
        "data.loc[:, 'site_id'] = le_site.transform(data.loc[:, 'site_id'])\n",
        "\n",
        "data.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nawWBptHyXp"
      },
      "source": [
        "test_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])\n",
        "for i in BSSID_FEATS:\n",
        "    test_data.loc[:,i] = le.transform(test_data.loc[:,i])\n",
        "    test_data.loc[:,i] = test_data.loc[:,i] + 1\n",
        "    \n",
        "test_data.loc[:, 'site_id'] = le_site.transform(test_data.loc[:, 'site_id'])\n",
        "\n",
        "test_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-7Nk_FH_5d"
      },
      "source": [
        "site_count = len(data['site_id'].unique())\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JefQyLY7IDdG"
      },
      "source": [
        "seed_everything(SEED)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCTLpK1CIE7t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1erbGwIJnH7"
      },
      "source": [
        "## Some EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li-SHH9WKsQx"
      },
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "max_iter = 10\n",
        "for i, (name, group) in enumerate(data.groupby(\"path\")):\n",
        "    sns.lineplot(data=group, y=RSSI_FEATS[0], x=range(group.shape[0]))\n",
        "    if i > max_iter:\n",
        "        break\n",
        "plt.figure(figsize=(10,3))\n",
        "for i, (name, group) in enumerate(data.groupby(\"path\")):\n",
        "    sns.lineplot(data=group, y=\"x\", x=range(group.shape[0]))\n",
        "    if i > max_iter:\n",
        "        break\n",
        "plt.figure(figsize=(10,3))\n",
        "for i, (name, group) in enumerate(data.groupby(\"path\")):\n",
        "    sns.lineplot(data=group, y=\"y\", x=range(group.shape[0]))\n",
        "    if i > max_iter:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkIaf4r-JnfM"
      },
      "source": [
        "tmp = data.loc[:,RSSI_FEATS]\n",
        "tmp.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3ltakG5IpS3"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTU96LMIIqrJ"
      },
      "source": [
        "class IndoorDataset(Dataset):\n",
        "    def __init__(self, data, flag='TRAIN'):\n",
        "        self.data = data\n",
        "        self.flag = flag\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    def __getitem__(self, index):\n",
        "        tmp_data = self.data.iloc[index]\n",
        "        if self.flag == 'TRAIN':\n",
        "            return {\n",
        "                'BSSID_FEATS':tmp_data[BSSID_FEATS].values.astype(float),\n",
        "                'RSSI_FEATS':tmp_data[RSSI_FEATS].values.astype(float),\n",
        "                'site_id':tmp_data['site_id'].astype(int),\n",
        "                'x':tmp_data['x'],\n",
        "                'y':tmp_data['y'],\n",
        "                'floor':tmp_data['floor'],\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'BSSID_FEATS':tmp_data[BSSID_FEATS].values.astype(float),\n",
        "                'RSSI_FEATS':tmp_data[RSSI_FEATS].values.astype(float),\n",
        "                'site_id':tmp_data['site_id'].astype(int)\n",
        "            }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ehQOeMKI2mJ"
      },
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim = 64, seq_len=20):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.emb_BSSID_FEATS = nn.Embedding(wifi_bssids_size, embedding_dim)\n",
        "        self.emb_site_id = nn.Embedding(site_count, 2)\n",
        "        self.lstm1 = nn.LSTM(input_size=256,hidden_size=128, dropout=0.3, bidirectional=False)\n",
        "        self.lstm2 = nn.LSTM(input_size=128,hidden_size=16, dropout=0.1, bidirectional=False)\n",
        "        self.lr = nn.Linear(NUM_FEATS, NUM_FEATS * embedding_dim)\n",
        "        self.lr1 = nn.Linear(2562, 256)\n",
        "        self.lr_xy = nn.Linear(16, 2)\n",
        "        self.lr_floor = nn.Linear(16, 1)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(NUM_FEATS)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(2562)\n",
        "        self.batch_norm3 = nn.BatchNorm1d(1)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x_bssid = self.emb_BSSID_FEATS(x['BSSID_FEATS'])\n",
        "        x_bssid = torch.flatten(x_bssid, start_dim=-2)\n",
        "        \n",
        "        x_site_id = self.emb_site_id(x['site_id'])\n",
        "        x_site_id = torch.flatten(x_site_id, start_dim=-1)\n",
        "        x_rssi = self.batch_norm1(x['RSSI_FEATS'])\n",
        "        x_rssi = self.lr(x_rssi)\n",
        "        x_rssi = torch.relu(x_rssi)\n",
        "        \n",
        "        x = torch.cat([x_bssid, x_site_id, x_rssi], dim=-1)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.lr1(x))\n",
        "\n",
        "        x = x.unsqueeze(-2)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x = torch.relu(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x = torch.relu(x)\n",
        "        xy = self.lr_xy(x)\n",
        "        floor = self.lr_floor(x)\n",
        "        floor = torch.relu(floor)\n",
        "        return xy.squeeze(-2), floor.squeeze(-2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG8UZ8Htkltz"
      },
      "source": [
        "def evaluate(net, data_loader,  device='cuda'):\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    x_list = []\n",
        "    y_list = []\n",
        "    floor_list = []\n",
        "    prexs_list = []\n",
        "    preys_list = []\n",
        "    prefloors_list = []\n",
        "    for d in tqdm(data_loader):\n",
        "        data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "        data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "        data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "        x = d['x'].to(device).float()\n",
        "        y = d['y'].to(device).float()\n",
        "        floor = d['floor'].to(device).long()\n",
        "        x_list.append(x.cpu().detach().numpy())\n",
        "        y_list.append(y.cpu().detach().numpy())\n",
        "        floor_list.append(floor.cpu().detach().numpy())\n",
        "        xy, floor = net(data_dict)\n",
        "        prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "        preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "        prefloors_list.append(floor.squeeze().cpu().detach().numpy())\n",
        "    x = np.concatenate(x_list)\n",
        "    y = np.concatenate(y_list)\n",
        "    floor = np.concatenate(floor_list)\n",
        "    prexs = np.concatenate(prexs_list)\n",
        "    preys =np.concatenate(preys_list)\n",
        "    prefloors = np.concatenate(prefloors_list)\n",
        "    eval_score = comp_metric(x, y, floor, prexs, preys, prefloors)\n",
        "    return eval_score\n",
        "def get_result(net, data_loader, device='cuda'):\n",
        "    net.eval()\n",
        "    net.to(device)\n",
        "    prexs_list = []\n",
        "    preys_list = []\n",
        "    prefloors_list = []\n",
        "    data_dict = {}\n",
        "    for d in tqdm(data_loader):\n",
        "        data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "        data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "        data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "        xy, floor = net(data_dict)\n",
        "        prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "        preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "        prefloors_list.append(floor.squeeze(-1).cpu().detach().numpy())\n",
        "    prexs = np.concatenate(prexs_list)\n",
        "    preys =np.concatenate(preys_list)\n",
        "    prefloors = np.concatenate(prefloors_list)\n",
        "    return prexs, preys, prefloors"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeeTEr3ClZY2"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "6zK8YeGfklwS",
        "outputId": "92dd5815-209d-43c4-d60c-52e715f6c999"
      },
      "source": [
        "%memit\n",
        "score_df = pd.DataFrame()\n",
        "oof = list()\n",
        "predictions = list()\n",
        "\n",
        "oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n",
        "preds_x, preds_y = 0, 0\n",
        "preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED).split(data.loc[:, 'path'], data.loc[:, 'path'])):\n",
        "\n",
        "    train_data = data.loc[trn_idx]\n",
        "    valid_data = data.loc[val_idx]\n",
        "    train_dataset = IndoorDataset(train_data)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=6)\n",
        "    valid_dataset = IndoorDataset(valid_data)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=True, num_workers=6)\n",
        "    test_dataset = IndoorDataset(test_data, 'TEST')\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=6)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    net = SimpleLSTM()\n",
        "    net = net.to(device)\n",
        "\n",
        "    mse = nn.MSELoss()\n",
        "    mse = mse.to(device)\n",
        "    optim = torch.optim.Adam(net.parameters(), lr=5e-3)\n",
        "\n",
        "    data_dict ={}\n",
        "    best_loss = 1000\n",
        "    num_epochs = 1\n",
        "    best_epoch = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        losses = []\n",
        "        pbar = tqdm(train_dataloader, position=0)\n",
        "        for d in pbar:\n",
        "            data_dict = {}\n",
        "            data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "            data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "            data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "            x = d['x'].to(device).float().unsqueeze(-1)\n",
        "            y = d['y'].to(device).float().unsqueeze(-1)\n",
        "            floor = d['floor'].to(device).long()\n",
        "            xy, floor = net(data_dict)\n",
        "            label = torch.cat([x, y], dim=-1)\n",
        "            loss = mse(xy, label)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            losses.append(loss.cpu().detach().numpy())\n",
        "            pbar.set_description(f'loss:{np.mean(losses)}')\n",
        "            data_dict['BSSID_FEATS'] = data_dict['BSSID_FEATS'].detach()\n",
        "            data_dict['RSSI_FEATS'] = data_dict['RSSI_FEATS'].detach()\n",
        "            data_dict['site_id'] = data_dict['site_id'].detach()\n",
        "            del x, y, xy, floor, label\n",
        "            torch.cuda.empty_cache()\n",
        "        score = evaluate(net, valid_dataloader, device)\n",
        "        if score < best_loss:\n",
        "            best_loss = score\n",
        "            best_epoch = epoch\n",
        "            best_model = copy.deepcopy(net)\n",
        "        if best_epoch + 2<epoch:\n",
        "            break\n",
        "        print(\"*=\"*50)\n",
        "        print(f\"fold {fold} EPOCH {epoch}: mean position error {score}\")\n",
        "        print(\"*=\"*50)\n",
        "    test_x, test_y, test_floor = get_result(best_model, test_dataloader, device)\n",
        "    preds_f_arr[:,fold] = test_floor\n",
        "    preds_x += test_x\n",
        "    preds_y += test_y"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 5736.76 MiB, increment: 0.01 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "loss:11285.6982421875:   5%|▍         | 1335/29039 [04:13<155:51:02, 20.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2156e94b2c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BSSID_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BSSID_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RSSI_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RSSI_FEATS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 351) is killed by signal: Killed. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzEs4cXZklyu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBedrYYkkciP"
      },
      "source": [
        "## Check Tensor Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpqo-9DVDs-"
      },
      "source": [
        "tmp = data.loc[:9,BSSID_FEATS]\n",
        "tmp_ids = []\n",
        "for i in range(20):\n",
        "    tmp_ids.extend(tmp.iloc[:,i].values.tolist())\n",
        "tmp_ids = len(list(set(tmp_ids)))\n",
        "_emb = nn.Embedding(wifi_bssids_size, 64)\n",
        "_res = _emb(torch.tensor(tmp.values.astype(float)).long())\n",
        "_res = torch.flatten(_res, start_dim=-2)\n",
        "#torch.tensor(tmp.values).size()\n",
        "\n",
        "tmp2 = data.loc[:9,RSSI_FEATS]\n",
        "tmp2_ids = []\n",
        "for i in range(20):\n",
        "    tmp2_ids.extend(tmp2.iloc[:,i].values.tolist())\n",
        "tmp2_ids = len(list(set(tmp2_ids)))\n",
        "lr = nn.Linear(20, 1280)\n",
        "_res2 = lr(torch.tensor(tmp2.values.astype(float)).float())\n",
        "\n",
        "tmp3 = data.loc[:9,\"site_id\"]\n",
        "_emb2 = nn.Embedding(site_count, 2)\n",
        "_res3 = _emb2(torch.tensor(tmp3.values.astype(float)).long())\n",
        "_res3 = torch.flatten(_res3, start_dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXT4mIq2VU4g"
      },
      "source": [
        "_res.size(), _res2.size(), _res3.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1krRsdrxZrca"
      },
      "source": [
        "_all = torch.cat([_res, _res2, _res3], dim=-1)\n",
        "_all = nn.Linear(2562, 256)(_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zB61jo8btzQ"
      },
      "source": [
        "_all.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW-xJQ7Qcr86"
      },
      "source": [
        "_un = _all.unsqueeze(-2)\n",
        "_un.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUPdtfyTfPPD"
      },
      "source": [
        "_tr = _un.transpose(0, 1)\n",
        "_tr.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgQBw3x0fbOv"
      },
      "source": [
        "_lstm1 = nn.LSTM(input_size=256,hidden_size=128, dropout=0.3, bidirectional=False)\n",
        "_ls1, _ = _lstm1(_tr)\n",
        "_ls1.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQBxHWDVgKZj"
      },
      "source": [
        "_xy = _ls1.transpose(0, 1)\n",
        "_xy = nn.Linear(128,2)(_xy)\n",
        "_xy.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzbiAEwJn2_o"
      },
      "source": [
        "_xy.squeeze(-2).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXPhtXcZoA5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}